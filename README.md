# Smart Note - AI-Powered Text Summarization ğŸ“ğŸ¤–

[![Python](https://img.shields.io/badge/python-3.10+-blue)](https://www.python.org/)  
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Spaces-orange)](https://huggingface.co/spaces/zahraa12355/smart_note)

Welcome to **Smart Note**, a lightweight and effective AI-powered text summarization app built with **Gradio**!  
Quickly digest meeting notes, articles, or any long text with concise summaries.

---

## ğŸ”¹ Features

- AI-powered text summarization
- Easy-to-use web interface via Gradio
- Lightweight and fast
- Runs locally or deployed on Hugging Face Spaces

---
## ğŸ”¹ Live Demo

Try the live app here:  
[Smart Note on Hugging Face Spaces](https://huggingface.co/spaces/zahraa12355/smart_note)

## ğŸ”¹ Project Structure

- `app.py` - Runs the Gradio interface for text summarization  
- `requirements.txt` - Lists all Python dependencies for the project  
- `README.md` - Contains project description and instructions  

  ---

# Smart Note - AI-Powered Text Summarization ğŸ“ğŸ¤–

Smart Note is a smart meeting notes summarization app powered by **Hugging Face** models and **Gradio**.  
It quickly converts long textâ€”like meeting notes or articlesâ€”into concise summaries.

---

## ğŸ”¹ Live Demo

Try the app live here:  
[Smart Note on Hugging Face Spaces](https://huggingface.co/spaces/zahraa12355/smart_note)

---
## ğŸ”¹ Run Locally

Follow these steps to run Smart Note on your local machine:

1. **Clone the repository:**

```bash
   git clone https://github.com/zaralrubaie/-smart-meeting-notes-by-LLM-.git
   cd smart_note
```
2. Install dependencies:
 ```bash
pip install -r requirements.txt
```
## ğŸ”¹ Limitations

- Summarization may take longer for longer or complex texts.  
- Running the model locally may be slow if your computer lacks a powerful GPU or sufficient memory.  
- This project uses the pretrained model for **inference only**; training large models locally is resource-intensive and not supported.  
- When using the live app on Hugging Face Spaces, inference time may also be affected by **server load** and **internet speed**.
